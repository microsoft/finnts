---
title: "Models Used in finnts"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{models-used-in-finnts}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r echo = FALSE, message = FALSE}
library(reactable)
library(dplyr)

reactable::reactable(
  data.frame() %>%
    rbind(data.frame(Model = "arima", Type = "univariate, local", Underlying.Package = "modeltime, forecast", Description = "Regression model that is based on finding relationships between lagged values of the target variable you are trying to forecast.")) %>%
    rbind(data.frame(Model = "arima-boost", Type = "multivariate, local", Underlying.Package = "modeltime, forecast, xgboost", Description = "Arima model (refer to arima) that models the trend compoent of target variable, then uses xgboost model (refer to xgboost) to train on the remaining residuals.")) %>%
    rbind(data.frame(Model = "cubist", Type = "multivariate, local, global, ensemble", Underlying.Package = "rules", Description = "Hybrid of tree based and linear regression approach. Many decision trees are built, but regression coefficients are used at each terminal node instead of averging values in other tree based approaches.")) %>%
    rbind(data.frame(Model = "croston", Type = "univariate, local", Underlying.Package = "modeltime, forecast", Description = "Useful for intermittent demand forecasting, aka when there are a lot of periods of zero values. Involves simple exponential smoothing on non-zero values of target variable and another application of seasonal exponential smoothing on periods between non-zero elements of the target variable. Refer to ets for more details on exponential smoothing.")) %>%
    rbind(data.frame(Model = "deepar", Type = "univariate, local, global", Underlying.Package = "modeltime.gluonts, reticulate, gluonts and torch (Python)", Description = "Autoregressive neural network (deep learning).")) %>%
    rbind(data.frame(Model = "ets", Type = "univariate, local", Underlying.Package = "modeltime, forecast", Description = "Forecasts produced using exponential smoothing methods are weighted averages of past observations, with the weights decaying exponentially as the observations get older. Exponential smoothing models try to forecast the components of a time series which can be broken down in to error, trend, and seasonality. These components can be forecasted separately then either added or multiplied together to get the final forecast output.")) %>%
    rbind(data.frame(Model = "glmnet", Type = "multivariate, local, global, ensemble", Underlying.Package = "parsnip, glmnet", Description = "Linear regression (line of best fit) with regularization to help prevent overfitting and built in variable selection.")) %>%
    rbind(data.frame(Model = "mars", Type = "multivariate, local, global", Underlying.Package = "parsnip, earth", Description = "An extension to linear regression that captures nonlinearities and interactions between variables.")) %>%
    rbind(data.frame(Model = "meanf", Type = "univariate, local", Underlying.Package = "modeltime, forecast", Description = "Simple average of previous year of target variable values.")) %>%
    rbind(data.frame(Model = "nbeats", Type = "univariate, local, global", Underlying.Package = "modeltime.gluonts, reticulate, gluonts (Python)", Description = "Another neural network (deep learning).")) %>%
    rbind(data.frame(Model = "nnetar", Type = "univariate, local", Underlying.Package = "modeltime, forecast", Description = "A neural network autoregression model is a traditional feed forward neural network (sometimes called an perceptron) that is fed by lagged values of the historical data set (similar to ARIMA).")) %>%
    rbind(data.frame(Model = "nnetar-xregs", Type = "multivariate, local", Underlying.Package = "modeltime, forecast", Description = "Same approach as nnetar but can incorporate other features in addition to the target variable, like external regressors and date features.")) %>%
    rbind(data.frame(Model = "prophet", Type = "univariate, local", Underlying.Package = "modeltime, prophet", Description = "Developed by Facebook, it's based on a generalized additive model (GAM): GAMs are simply a class of statistical Models in which the usual linear relationship between the target variable and predictors are replaced by several non linear smooth functions to model and capture the non linearities in the data.")) %>%
    rbind(data.frame(Model = "prophet-boost", Type = "multivariate, local", Underlying.Package = "modeltime, prophet, xgboost", Description = "Prophet model (refer to prophet) that models the trend compoent of target variable, then uses xgboost model (refer to xgboost) to train on the remaining residuals.")) %>%
    rbind(data.frame(Model = "prophet-xregs", Type = "multivariate, local", Underlying.Package = "modeltime, prophet", Description = "Prophet model that incorporates external regressors and other engineered features.")) %>%
    rbind(data.frame(Model = "snaive", Type = "univariate, local", Underlying.Package = "modeltime, forecast", Description = "Simple model that takes the value from the same period in the previous year.")) %>%
    rbind(data.frame(Model = "stlm-arima", Type = "univariate, local", Underlying.Package = "modeltime, forecast", Description = "Applies an STL decomposition (breaks out target variable into seasonal, trend, and error/residual/remainder components), models the seasonally adjusted data, reseasonalizes, and returns the forecasts. An arima model (refer to arima) is used in forecasting the seasonaly adjusted data.")) %>%
    rbind(data.frame(Model = "stlm-ets", Type = "univariate, local", Underlying.Package = "modeltime, forecast", Description = "Applies an STL decomposition (breaks out target variable into seasonal, trend, and error/residual/remainder components), models the seasonally adjusted data, reseasonalizes, and returns the forecasts. An ets model (refer to ets) is used in forecasting the seasonaly adjusted data.")) %>%
    rbind(data.frame(Model = "svm-poly", Type = "multivariate, local, global, ensemble", Underlying.Package = "parsnip, kernlab", Description = "Uses a nonlinear function, specifically a polynomial function, to create a regression line of the target variable.")) %>%
    rbind(data.frame(Model = "svm-rbf", Type = "multivariate, local, global, ensemble", Underlying.Package = "parsnip, kernlab", Description = "Uses a nonlinear function, specifically a radial basis function, to create a regression line of the target variable.")) %>%
    rbind(data.frame(Model = "tbats", Type = "univariate, local", Underlying.Package = "modeltime, forecast", Description = "A spin off of the traditional ets model (refer to ets), with some additional components to capture multiple seasonalities.")) %>%
    rbind(data.frame(Model = "theta", Type = "univariate, local", Underlying.Package = "modeltime, forecast", Description = "Theta is similar to exponential smoothing (refer to ets) but with another component called drift. Adding drift to exponential smoothing allows the forecast to increase or decrease over time, where the amount of change over time (called the drift) is set to be the average change seen within the historical data.")) %>%
    rbind(data.frame(Model = "xgboost", Type = "multivariate, local, global, ensemble", Underlying.Package = "parsnip, xgboost", Description = "Builds many decision trees (similar to random forests), but predictions that are initially inaccurate are applied more weight in subsequent training rounds to increase accuracy across all predictions."))
  , 
  defaultColDef = colDef(
    header = function(value) gsub(".", " ", value, fixed = TRUE),
    cell = function(value) format(value, nsmall = 1),
    align = "center",
    minWidth = 70,
    headerStyle = list(background = "#f7f7f8")
  ),
  columns = list(
    Description = colDef(minWidth = 140, align = "left")  # overrides the default
  ),
  bordered = TRUE,
  highlight = TRUE
)

```

### Univariate vs Multivariate Models

* **Univariate models** only use the date and target variable values when producing a forecast. They are mostly common on various statistical forecasting models like arima and ets. 

* **Multivariate models** leverage many features when producing a forecast, provided as input data before model training. These features can be automatically created using internal feature engineering techniques within the package, or provided as external regressors. Most common machine learning models today, like xgboost and svm-poly, are multivariate models. An important thing to note is that multivariate models provided in the package can leverage different recipes of feature engineering, that contain different techniques of creating features. These can be identified by seeing the letter "R" followed by a number like "1" or "2" added onto the end of multivariate models. For example, "glmnet-R1" uses a specific recipe to engineer features before feeding the data into a glmnet model to train. 

### Global vs Local Models

* **Global models** take the entire dataset across all individual time series and model them all at once within a single model. Global models are only ran if the input data contains more than one individual time series. 

* **Local models** take each individual time series from the input data and model them separately. 

### Ensemble Models

Ensemble models are trained on predictions made by individual models. For example, a "glmmet-ensemble" model takes forecasts made by each individual model and feeds them as training data into a glmnet model. They also contain features related to date and forecasting horizon.

### Deep Learning Models

The package contains multiple deep learning models that initially come from a python package called gluonts, which is developed by Amazon. They are called into R through a package called reticulate, which let's python code run within R. In order to make these models run within R, you will need to install the proper python libraries, check out [modeltime.gluonts](https://business-science.github.io/modeltime.gluonts/articles/managing-envs.html) to learn more about how to install everything properly. 

## Leveraging the Tidymodels Framework

Most of the models within the package are built on a fantastic time series library called [modeltime](https://business-science.github.io/modeltime/), which was built on top [tidymodels](https://www.tidymodels.org/). Tidymodels is a fantastic series of packages that help in feature engineering (recipes), hyperparameter tuning (tune), model training (parsnip), and backtesting (resample). Big shout out to the modeltime and tidymodels teams for being the shoulders this package stands on!
